{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# AWS BEDROCK API EXAMPLE",
   "id": "9564b2bd12225f62"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-23T09:56:14.903695Z",
     "start_time": "2025-03-23T09:56:14.778995Z"
    }
   },
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "\n",
    "from bedrock import BedrockWrapper\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "aws_access_key_id = os.environ.get(\"aws_access_key_id\")\n",
    "aws_secret_access_key = os.environ.get(\"aws_secret_access_key\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Generative AI with large language models available on AWS",
   "id": "43c33b3883537bc4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:05:43.318302Z",
     "start_time": "2025-03-23T10:05:42.955364Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate(prompt: str) -> str:\n",
    "    boto3_bedrock = boto3.client(\n",
    "        'bedrock-runtime',\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        region_name=\"eu-central-1\")\n",
    "\n",
    "    body = json.dumps({\"prompt\": prompt, \"max_tokens_to_sample\": 300})\n",
    "\n",
    "    modelId = 'anthropic.claude-instant-v1'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    response = boto3_bedrock.invoke_model(body=body, modelId=modelId, contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    return response_body['completion']\n",
    "\n",
    "response = generate(\"Human:2+2=? Assistant:\")\n",
    "print(response)"
   ],
   "id": "78e861db4d080f81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Multimodal LLM",
   "id": "9b9f4ef597f4f30e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T10:14:24.689790Z",
     "start_time": "2025-03-23T10:14:18.416615Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import base64\n",
    "\n",
    "def generate_multimodal(image_path: str):\n",
    "    boto3_bedrock = boto3.client(\n",
    "        'bedrock-runtime',\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        region_name=\"eu-central-1\")\n",
    "    image_base64 = base64.b64encode(open(image_path, 'rb').read()).decode('utf-8')\n",
    "    body = json.dumps(\n",
    "        {\n",
    "            \"anthropic_version\": \"bedrock-2023-05-31\",\n",
    "            \"max_tokens\": 1000,\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": [\n",
    "                        {\n",
    "                            \"type\": \"image\",\n",
    "                            \"source\": {\n",
    "                                \"type\": \"base64\",\n",
    "                                \"media_type\": \"image/jpeg\",\n",
    "                                \"data\": image_base64\n",
    "                            }\n",
    "                        },\n",
    "                        {\n",
    "                            \"type\": \"text\",\n",
    "                            \"text\": \"What's in this image?\"\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    modelId = 'anthropic.claude-3-5-sonnet-20240620-v1:0'\n",
    "    contentType = 'application/json'\n",
    "\n",
    "    response = boto3_bedrock.invoke_model(body=body, modelId=modelId, contentType=contentType)\n",
    "    response_body = json.loads(response.get('body').read())\n",
    "\n",
    "    return response_body\n",
    "\n",
    "response = generate_multimodal('picture.jpg')\n",
    "\n",
    "print(response)"
   ],
   "id": "9b1ccd9f07808991",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'msg_bdrk_01CMVx7ebAQMW9PuevC34C6J', 'type': 'message', 'role': 'assistant', 'model': 'claude-3-5-sonnet-20240620', 'content': [{'type': 'text', 'text': \"This image shows a close-up portrait of a brown cow. The cow has a distinctive white marking down the center of its face, contrasting with its reddish-brown fur. Its eyes are clearly visible, giving it an alert and curious expression. The cow's ears are tagged with yellow identification tags, visible on both sides. One tag shows the number 5848, indicating this is likely a farm animal being tracked. The cow has a somewhat shaggy, fluffy appearance, especially noticeable in the tuft of hair on top of its head. The background is blurred, but appears to be an outdoor setting, possibly a farm or pasture. This image captures the cow's individual character and the details of its facial features very well.\"}], 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 385, 'output_tokens': 158}}\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Get model details via API",
   "id": "ce22b9ebf52bd30d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-23T09:56:19.334928Z",
     "start_time": "2025-03-23T09:56:18.982069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def usage_demo():\n",
    "    \"\"\"\n",
    "    Shows how to list the available foundation models.\n",
    "    This demonstration gets the list of available foundation models and\n",
    "    prints their respective summaries.\n",
    "    \"\"\"\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    print(\"-\" * 88)\n",
    "    print(\"Welcome to the Amazon Bedrock demo.\")\n",
    "    print(\"-\" * 88)\n",
    "\n",
    "    bedrock_client = boto3.client(\n",
    "        service_name=\"bedrock\",\n",
    "        aws_access_key_id=aws_access_key_id,\n",
    "        aws_secret_access_key=aws_secret_access_key,\n",
    "        region_name=\"eu-central-1\"\n",
    "    )\n",
    "\n",
    "    wrapper = BedrockWrapper(bedrock_client)\n",
    "\n",
    "    print(\"Listing the available foundation models.\")\n",
    "\n",
    "    try:\n",
    "        for model in wrapper.list_foundation_models():\n",
    "            print_model_details(model)\n",
    "    except ClientError:\n",
    "        logger.exception(\"Couldn't list foundation models.\")\n",
    "        raise\n",
    "\n",
    "    print(\"Getting the details of an individual foundation model.\")\n",
    "\n",
    "    model_id = \"amazon.titan-embed-text-v1\"\n",
    "\n",
    "    try:\n",
    "        print_model_details(wrapper.get_foundation_model(model_id))\n",
    "    except ClientError:\n",
    "        logger.exception(f\"Couldn't get foundation model {model_id}.\")\n",
    "        raise\n",
    "\n",
    "\n",
    "def print_model_details(model):\n",
    "    print(\"\\n\" + \"=\" * 42)\n",
    "    print(f' Model: {model[\"modelId\"]}')\n",
    "    print(\"-\" * 42)\n",
    "    print(f' Name: {model[\"modelName\"]}')\n",
    "    print(f' Provider: {model[\"providerName\"]}')\n",
    "    print(f' Model ARN: {model[\"modelArn\"]}')\n",
    "    print(f' Lifecycle status: {model[\"modelLifecycle\"][\"status\"]}')\n",
    "    print(f' Input modalities: {model[\"inputModalities\"]}')\n",
    "    print(f' Output modalities: {model[\"outputModalities\"]}')\n",
    "    print(f' Supported customizations: {model[\"customizationsSupported\"]}')\n",
    "    print(f' Supported inference types: {model[\"inferenceTypesSupported\"]}')\n",
    "    if \"responseStreamingSupported\" in model:\n",
    "        print(f' Response streaming supported: {model[\"responseStreamingSupported\"]}')\n",
    "\n",
    "    print(\"=\" * 42)\n",
    "\n",
    "usage_demo()"
   ],
   "id": "83fff4f1e26f8f0b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------\n",
      "Welcome to the Amazon Bedrock demo.\n",
      "----------------------------------------------------------------------------------------\n",
      "Listing the available foundation models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bedrock:Got 26 foundation models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========================================\n",
      " Model: amazon.titan-text-express-v1:0:8k\n",
      "------------------------------------------\n",
      " Name: Titan Text G1 - Express\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/amazon.titan-text-express-v1:0:8k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: []\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-text-express-v1\n",
      "------------------------------------------\n",
      " Name: Titan Text G1 - Express\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/amazon.titan-text-express-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-text-lite-v1:0:4k\n",
      "------------------------------------------\n",
      " Name: Titan Text G1 - Lite\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/amazon.titan-text-lite-v1:0:4k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['PROVISIONED']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-text-lite-v1\n",
      "------------------------------------------\n",
      " Name: Titan Text G1 - Lite\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/amazon.titan-text-lite-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-embed-text-v1:2:8k\n",
      "------------------------------------------\n",
      " Name: Titan Embeddings G1 - Text\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/amazon.titan-embed-text-v1:2:8k\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: []\n",
      " Supported inference types: []\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-embed-text-v1\n",
      "------------------------------------------\n",
      " Name: Titan Embeddings G1 - Text\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/amazon.titan-embed-text-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-embed-image-v1:0\n",
      "------------------------------------------\n",
      " Name: Titan Multimodal Embeddings G1\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/amazon.titan-embed-image-v1:0\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT', 'IMAGE']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['PROVISIONED']\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-embed-image-v1\n",
      "------------------------------------------\n",
      " Name: Titan Multimodal Embeddings G1\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/amazon.titan-embed-image-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT', 'IMAGE']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-embed-text-v2:0\n",
      "------------------------------------------\n",
      " Name: Titan Embeddings G2 - Text\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/amazon.titan-embed-text-v2:0\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.rerank-v1:0\n",
      "------------------------------------------\n",
      " Name: Rerank 1.0\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/amazon.rerank-v1:0\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.nova-pro-v1:0\n",
      "------------------------------------------\n",
      " Name: Nova Pro\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/amazon.nova-pro-v1:0\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT', 'IMAGE', 'VIDEO']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['INFERENCE_PROFILE']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.nova-lite-v1:0\n",
      "------------------------------------------\n",
      " Name: Nova Lite\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/amazon.nova-lite-v1:0\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT', 'IMAGE', 'VIDEO']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['INFERENCE_PROFILE']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: amazon.nova-micro-v1:0\n",
      "------------------------------------------\n",
      " Name: Nova Micro\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/amazon.nova-micro-v1:0\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['INFERENCE_PROFILE']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-instant-v1\n",
      "------------------------------------------\n",
      " Name: Claude Instant\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/anthropic.claude-instant-v1\n",
      " Lifecycle status: LEGACY\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-v2:1:18k\n",
      "------------------------------------------\n",
      " Name: Claude\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/anthropic.claude-v2:1:18k\n",
      " Lifecycle status: LEGACY\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['PROVISIONED']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-v2:1:200k\n",
      "------------------------------------------\n",
      " Name: Claude\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/anthropic.claude-v2:1:200k\n",
      " Lifecycle status: LEGACY\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['PROVISIONED']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-v2:1\n",
      "------------------------------------------\n",
      " Name: Claude\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/anthropic.claude-v2:1\n",
      " Lifecycle status: LEGACY\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-v2\n",
      "------------------------------------------\n",
      " Name: Claude\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/anthropic.claude-v2\n",
      " Lifecycle status: LEGACY\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-3-sonnet-20240229-v1:0\n",
      "------------------------------------------\n",
      " Name: Claude 3 Sonnet\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/anthropic.claude-3-sonnet-20240229-v1:0\n",
      " Lifecycle status: LEGACY\n",
      " Input modalities: ['TEXT', 'IMAGE']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-3-haiku-20240307-v1:0\n",
      "------------------------------------------\n",
      " Name: Claude 3 Haiku\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/anthropic.claude-3-haiku-20240307-v1:0\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT', 'IMAGE']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      "------------------------------------------\n",
      " Name: Claude 3.5 Sonnet\n",
      " Provider: Anthropic\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/anthropic.claude-3-5-sonnet-20240620-v1:0\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT', 'IMAGE']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: cohere.embed-english-v3\n",
      "------------------------------------------\n",
      " Name: Embed English\n",
      " Provider: Cohere\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/cohere.embed-english-v3\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: cohere.embed-multilingual-v3\n",
      "------------------------------------------\n",
      " Name: Embed Multilingual\n",
      " Provider: Cohere\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/cohere.embed-multilingual-v3\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: cohere.rerank-v3-5:0\n",
      "------------------------------------------\n",
      " Name: Rerank 3.5\n",
      " Provider: Cohere\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/cohere.rerank-v3-5:0\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: meta.llama3-2-1b-instruct-v1:0\n",
      "------------------------------------------\n",
      " Name: Llama 3.2 1B Instruct\n",
      " Provider: Meta\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/meta.llama3-2-1b-instruct-v1:0\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['INFERENCE_PROFILE']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "\n",
      "==========================================\n",
      " Model: meta.llama3-2-3b-instruct-v1:0\n",
      "------------------------------------------\n",
      " Name: Llama 3.2 3B Instruct\n",
      " Provider: Meta\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/meta.llama3-2-3b-instruct-v1:0\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['TEXT']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['INFERENCE_PROFILE']\n",
      " Response streaming supported: True\n",
      "==========================================\n",
      "Getting the details of an individual foundation model.\n",
      "\n",
      "==========================================\n",
      " Model: amazon.titan-embed-text-v1\n",
      "------------------------------------------\n",
      " Name: Titan Embeddings G1 - Text\n",
      " Provider: Amazon\n",
      " Model ARN: arn:aws:bedrock:eu-central-1::foundation-model/amazon.titan-embed-text-v1\n",
      " Lifecycle status: ACTIVE\n",
      " Input modalities: ['TEXT']\n",
      " Output modalities: ['EMBEDDING']\n",
      " Supported customizations: []\n",
      " Supported inference types: ['ON_DEMAND']\n",
      " Response streaming supported: False\n",
      "==========================================\n"
     ]
    }
   ],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
